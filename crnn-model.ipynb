{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2243895,"sourceType":"datasetVersion","datasetId":1347338},{"sourceId":7805061,"sourceType":"datasetVersion","datasetId":4570602},{"sourceId":7856396,"sourceType":"datasetVersion","datasetId":4607996}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.layers import LSTM, TimeDistributed, Dense, Flatten, Input, Dropout, Bidirectional\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\n\nclass DataLoader:\n    def __init__(self, dataset_dir, img_height, img_width, use_text_line_segmentation=True):\n        self.dataset_dir = dataset_dir\n        self.image_dir = os.path.join(dataset_dir, 'images')\n        self.transcriptions_file = os.path.join(dataset_dir, 'text', 'transcriptions.txt')\n        self.train_file = os.path.join(dataset_dir, 'partitions', 'train.txt')\n        self.validation_file = os.path.join(dataset_dir, 'partitions', 'validation.txt')\n        self.test_file = os.path.join(dataset_dir, 'partitions', 'test.txt')\n        self.img_height = img_height\n        self.img_width = img_width\n\n    def load_dataset(self):\n        transcriptions = self.load_transcriptions()\n        train_set = self.load_set(self.train_file)\n        validation_set = self.load_set(self.validation_file)\n        test_set = self.load_set(self.test_file)\n\n        return transcriptions, train_set, validation_set, test_set\n\n    def load_transcriptions(self):\n        transcriptions = {}\n        with open(self.transcriptions_file, 'r', encoding='utf-8') as file:\n            for line in file:\n                image_name, transcription = line.strip().split(\" \", 1)\n                transcriptions[image_name] = transcription\n        return transcriptions\n\n    def load_set(self, set_file):\n        set_list = []\n        with open(set_file, 'r') as file:\n            for line in file:\n                image_name = line.strip()\n                image_path = os.path.join(self.image_dir, f'{image_name}.png')\n                set_list.append(image_path)\n        return set_list\n\n    def load_images_and_labels(self, set_list, transcriptions):\n        images = []\n        labels = []\n        for image_path in set_list:\n            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n\n            # Binarization with adaptive thresholding\n            thresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n\n            # Noise reduction (optional)\n            denoised = cv2.medianBlur(thresh, 3)\n\n            # Since not using text line segmentation, resize the entire image\n            img = cv2.resize(img, (self.img_width, self.img_height))\n            images.append(img)\n\n            if images:  # Check if images list is not empty\n                images[-1] = images[-1] / 255.0  # Normalize pixel values\n\n            image_name = os.path.basename(image_path).split('.')[0]\n            transcription = transcriptions[image_name]\n            labels.append(transcription)\n\n        images = np.array(images).reshape(-1, self.img_height, self.img_width, 1)\n        return images, labels","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:38:29.389694Z","iopub.execute_input":"2024-04-07T07:38:29.390098Z","iopub.status.idle":"2024-04-07T07:38:50.495063Z","shell.execute_reply.started":"2024-04-07T07:38:29.390066Z","shell.execute_reply":"2024-04-07T07:38:50.493347Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-07 07:38:33.555769: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-07 07:38:33.555885: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-07 07:38:33.807659: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install keras-tuner","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:38:50.498646Z","iopub.execute_input":"2024-04-07T07:38:50.499571Z","iopub.status.idle":"2024-04-07T07:39:05.466667Z","shell.execute_reply.started":"2024-04-07T07:38:50.499518Z","shell.execute_reply":"2024-04-07T07:39:05.465422Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras-tuner in /opt/conda/lib/python3.10/site-packages (1.4.6)\nRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (3.0.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (2.31.0)\nRequirement already satisfied: kt-legacy in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (1.0.5)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (1.26.4)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (0.0.7)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (3.10.0)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (0.1.8)\nRequirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (0.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras-tuner) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (2024.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras->keras-tuner) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras->keras-tuner) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"def build_crnn_model(hp):\n    img_height = 32  # Fixed image height\n    img_width = 128  # Fixed image width\n    num_classes = 111  # Fixed number of classes\n\n    # Define search space for hyperparameters\n    conv_filters = hp.Int('conv_filters', min_value=32, max_value=128, step=16)\n    lstm_units = hp.Int('lstm_units', min_value=64, max_value=256, step=16)\n    dropout_rate = hp.Float('dropout_rate', min_value=0.0, max_value=0.5)\n    kernel_size = hp.Choice('kernel_size', values = [3,5])\n\n    model = keras.Sequential()\n\n    # Convolutional layers with HP for filters\n    model.add(Conv2D(conv_filters, kernel_size, activation='relu', input_shape=(img_height, img_width, 1)))\n    #model.add(Dropout(dropout_rate))\n    model.add(MaxPooling2D((2, 2)))\n    #model.add(BatchNormalization())\n\n    model.add(Conv2D(conv_filters, kernel_size, activation='relu'))\n    #model.add(Dropout(dropout_rate))\n    model.add(MaxPooling2D((2, 2)))\n    #model.add(BatchNormalization())\n\n    #model.add(Conv2D(conv_filters, kernel_size, activation='relu'))\n    #model.add(Dropout(dropout_rate))\n    #model.add(MaxPooling2D((2, 2)))\n    #model.add(BatchNormalization())\n\n    # Recurrent layers\n    model.add(TimeDistributed(Flatten()))\n    model.add(Bidirectional(LSTM(lstm_units, return_sequences=True, dropout=dropout_rate)))\n    model.add(Bidirectional(LSTM(lstm_units, return_sequences=True, dropout=dropout_rate)))\n    model.add(Bidirectional(LSTM(lstm_units, return_sequences=True, dropout=dropout_rate)))\n    #model.add(Bidirectional(LSTM(lstm_units // 2)))  # Reduce units in final LSTM\n\n    model.add(Flatten())\n    model.add(Dense(max_len, activation='softmax'))\n\n    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-0, 1e-2])),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:39:05.468725Z","iopub.execute_input":"2024-04-07T07:39:05.469180Z","iopub.status.idle":"2024-04-07T07:39:05.481015Z","shell.execute_reply.started":"2024-04-07T07:39:05.469144Z","shell.execute_reply":"2024-04-07T07:39:05.480163Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Set the path to your dataset\ndataset_dir = '/kaggle/input/general-dataset'\nimg_height = 32\nimg_width = 128\n\n# Initialize data loader\ndata_loader = DataLoader(dataset_dir, img_height, img_width)\n\n# Load transcriptions and datasets\ntranscriptions, train_set, validation_set, test_set = data_loader.load_dataset()\n\n# Load actual images and labels\ntrain_images, train_labels = data_loader.load_images_and_labels(train_set, transcriptions)\nvalidation_images, validation_labels = data_loader.load_images_and_labels(validation_set, transcriptions)\n\nprint(train_images.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:39:05.482196Z","iopub.execute_input":"2024-04-07T07:39:05.482468Z","iopub.status.idle":"2024-04-07T07:41:34.564126Z","shell.execute_reply.started":"2024-04-07T07:39:05.482442Z","shell.execute_reply":"2024-04-07T07:41:34.563080Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(9000, 32, 128, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert labels to numerical representatio\nchar_to_index = {}\nindex = 0\nfor text in transcriptions.values():\n    for char in text:\n        if char not in char_to_index:\n            char_to_index[char] = index\n            index += 1\n            \ndef label_to_index(label):\n    return [char_to_index[char] if char in char_to_index else char_to_index['<unknown>'] for char in label]\nnum_classes = len(char_to_index)\nprint(num_classes)\n\n'''train_labels_encoded = []\nfor label in train_labels:\n    encoded_label = [char_to_index[char] for char in label]\n    encoded_label = to_categorical(encoded_label, num_classes=num_classes)\n    # Pad or truncate the encoded label to the maximum sequence length\n    encoded_label = pad_sequences([encoded_label], maxlen=max_len, padding='post')[0]\n    train_labels_encoded.append(encoded_label)\ntrain_labels_encoded = np.array(train_labels_encoded)\n\nvalidation_labels_encoded = []\nfor label in validation_labels:\n    encoded_label = [char_to_index[char] for char in label]\n    encoded_label = to_categorical(encoded_label, num_classes=num_classes)\n    # Pad or truncate the encoded label to the maximum sequence length\n    encoded_label = pad_sequences([encoded_label], maxlen=max_len, padding='post')[0]\n    validation_labels_encoded.append(encoded_label)\nvalidation_labels_encoded = np.array(validation_labels_encoded)'''\n\ntrain_labels_encoded = [label_to_index(label) for label in train_labels]\n#train_labels_encoded = np.array(train_labels_encoded)\nvalidation_labels_encoded = [label_to_index(label) for label in validation_labels]\n#validation_labels_encoded = np.array(validation_labels_encoded)\n\n# Pad sequences with zeros (adding zeros at the end)\ntrain_labels_padded = pad_sequences(train_labels_encoded, padding='post')\nvalidation_labels_padded = pad_sequences(validation_labels_encoded, padding='post')\n\n# Convert to NumPy arrays\ntrain_labels_array = np.array(train_labels_padded)\nvalidation_labels_array = np.array(validation_labels_padded)\n\n# Calculate the maximum sequence length\n#max_len = max(train_labels_array.shape[1], validation_labels_array.shape[1])\nmax_len = max(len(label) for label in train_labels + validation_labels)\n\n\n# Print shapes for verification\nprint(\"Train Images Shape:\", train_images.shape)\nprint(\"Train Labels Shape:\", train_labels_array.shape)\nprint(\"Validation Images Shape:\", validation_images.shape)\nprint(\"Validation Labels Shape:\", validation_labels_array.shape)\nprint(train_labels_padded.shape)\nprint(max_len)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:41:34.566755Z","iopub.execute_input":"2024-04-07T07:41:34.567092Z","iopub.status.idle":"2024-04-07T07:41:34.841981Z","shell.execute_reply.started":"2024-04-07T07:41:34.567063Z","shell.execute_reply":"2024-04-07T07:41:34.841073Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"111\nTrain Images Shape: (9000, 32, 128, 1)\nTrain Labels Shape: (9000, 74)\nValidation Images Shape: (1000, 32, 128, 1)\nValidation Labels Shape: (1000, 71)\n(9000, 74)\n74\n","output_type":"stream"}]},{"cell_type":"code","source":"from kerastuner import RandomSearch\nfrom kerastuner.engine.hyperparameters import HyperParameters\nfrom kerastuner import HyperModel\n\ntuner_search = RandomSearch(build_crnn_model, objective='val_accuracy', max_trials=5)\n\n#tuner_search.fit(train_images, train_labels_padded, epochs=10, validation_split=0.1)\n\ntuner_search.search(train_images,train_labels_padded,epochs=3,validation_split=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:48:50.219970Z","iopub.execute_input":"2024-04-07T07:48:50.220840Z","iopub.status.idle":"2024-04-07T07:48:50.235760Z","shell.execute_reply.started":"2024-04-07T07:48:50.220805Z","shell.execute_reply":"2024-04-07T07:48:50.234874Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Reloading Tuner from ./untitled_project/tuner0.json\n","output_type":"stream"}]},{"cell_type":"code","source":"model=tuner_search.get_best_models(num_models=1)[0]\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:48:56.030120Z","iopub.execute_input":"2024-04-07T07:48:56.030493Z","iopub.status.idle":"2024-04-07T07:48:56.816400Z","shell.execute_reply.started":"2024-04-07T07:48:56.030464Z","shell.execute_reply":"2024-04-07T07:48:56.815390Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m832\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m25,632\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m928\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m480\u001b[0m)         │     \u001b[38;5;34m2,244,480\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m480\u001b[0m)         │     \u001b[38;5;34m1,384,320\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m480\u001b[0m)         │     \u001b[38;5;34m1,384,320\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2400\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m)             │       \u001b[38;5;34m177,674\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,632</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">928</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,244,480</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,384,320</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,384,320</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2400</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">177,674</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,217,258\u001b[0m (19.90 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,217,258</span> (19.90 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,217,258\u001b[0m (19.90 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,217,258</span> (19.90 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"model.fit(train_images, train_labels_padded, epochs=10, validation_split=0.1, initial_epoch=3)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:49:01.245994Z","iopub.execute_input":"2024-04-07T07:49:01.246850Z","iopub.status.idle":"2024-04-07T07:50:35.616189Z","shell.execute_reply.started":"2024-04-07T07:49:01.246814Z","shell.execute_reply":"2024-04-07T07:50:35.615200Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 4/10\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 52ms/step - accuracy: 0.0178 - loss: 4008647.5000 - val_accuracy: 0.0256 - val_loss: 5526091.0000\nEpoch 5/10\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.0275 - loss: 6943677.5000 - val_accuracy: 0.0256 - val_loss: 6283909.0000\nEpoch 6/10\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.0170 - loss: 7249979.0000 - val_accuracy: 0.0256 - val_loss: 6403379.0000\nEpoch 7/10\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.0224 - loss: 8257271.0000 - val_accuracy: 0.0256 - val_loss: 7641455.5000\nEpoch 8/10\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0191 - loss: 9429448.0000 - val_accuracy: 0.0689 - val_loss: 8673196.0000\nEpoch 9/10\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.0233 - loss: 10349028.0000 - val_accuracy: 0.0256 - val_loss: 9916072.0000\nEpoch 10/10\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.0246 - loss: 12663228.0000 - val_accuracy: 0.0256 - val_loss: 11340088.0000\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7c350ccaead0>"},"metadata":{}}]}]}